---
title: "scraper"
author: "Szabolcs Kerekes"
date: "11/05/2019"
output: html_document
---

```{r setup, results="hide", message=F, warning = F}
library(tidyverse)
library(tidytext)
library(stringr)
library(ggplot2)
library(lubridate)
library(skimr)
library(purrr)
library(data.table)
library(logger)
library(caret)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r data_import, warning=FALSE, message=FALSE}
data <- read.csv('data/pitchfork_final.csv', stringsAsFactors = FALSE)
str(data)
head(data)
skim(data)
```

## Including Plots

You can also embed plots, for example:

```{r missing_values, warning=FALSE, message=FALSE}
data %>% filter(is.na(artist) == TRUE)

data <- data %>% filter(is.na(release_year) == FALSE)

data <- data %>% mutate(review_date = ymd(review_date))
max_date <- data %>% select(review_date) %>% drop_na() %>% head(1)
max_date <- max_date$review_date
data <- data %>% replace_na(list(review_date = max_date + 1, 
                                 bnm = FALSE,
                                 author_title = 'Other',
                                 genre = 'Other',
                                 label_name = 'Other',
                                 artist_name = 'NA_'))

data <- data %>% mutate(artist = as.factor(artist),
                genre = as.factor(genre),
                author_name = as.factor(author_name),
                author_title = as.factor(author_title),
                label_name = as.factor(label_name))

data <- data %>% filter(release_year >= 2016)
```

TBA

```{r parsing_text, warning=FALSE, message=FALSE}
unique(unlist(map(data$review_text, function(x) unique(unlist(strsplit(tolower(x), split = ""))))))

temp <- map(data$review_text, function(x){ 
  x <- str_replace_all(x, 'Best new music', '')
  x <- tolower(x)
  x <- str_replace_all(x, regex("[^a-z /n]*", perl = TRUE), '')
  return(x)
}) 

data$review_text <- unlist(temp)
```

TBA

```{r custom_stop_words, warning=FALSE, message=FALSE}
names <- gsub("([a-z])([A-Z])", "\\1 \\2", unique(data$artist))
names <- str_split(names, ' ')
names <- map(names, function(x) tolower(x))
names <- map(names, function(x) str_replace_all(x, regex("[^a-z /n]*", perl = TRUE), ''))

genres <- str_split(unique(data$genre), '\\/')
genres <- map(genres, function(x) tolower(x))
genres <- map(genres, function(x) str_replace_all(x, regex("[^a-z /n]*", perl = TRUE), ''))

custom_stop_words <- bind_rows(data_frame(word = c("album", "music", "songs", "band", "song",
                                                   "sounds", "albums", "sound", "record", "records", "time",
                                                   "bands", "feels", "makes", "voice",
                                                   "feel", "track", "tracks", "hes", "shes", "dont", "doesnt", 
                                                   "im", "raps", "rappers", "aint",
                                                   "artist", "artists", "isnt", unique(unlist(names)), unlist(genres)), 
                                          lexicon = c("custom")), stop_words)

```

TBA

```{r sentiment_scores, warning=FALSE, message=FALSE}
sent_afinn <- get_sentiments('afinn')

afinn_scores <- map(data$review_text, function(x){
  text <- strsplit(x, ' ')
  
  text <- data_frame('word' = unlist(text))
  
  text <- text %>% 
    filter(word != '') %>%
    anti_join(stop_words) %>% 
    inner_join(sent_afinn) %>% 
    summarise(afinn_score = mean(score) / 5)
  
  return(text$afinn_score)
})

data$afinn_score <- unlist(afinn_scores)

ggplot(data = data, aes(x = score, y = afinn_score)) +
  geom_point() +
  facet_wrap(~release_year) + 
  geom_smooth(method = 'lm') + 
  theme_bw() +
  labs(x = 'Review score', y = 'Sentiment score', 
       title = 'Review score vs. sentiment score', subtitle = '2016 to 2019, yearly breakdown')

ggsave('review_vs_sentiment1619.png')

ggplot(data = data, aes(x = score, y = afinn_score)) +
  geom_point(size = 0.1) +
  facet_wrap(~genre + release_year, ncol = 4) + 
  geom_smooth(method = 'lm') + 
  theme_bw() +
  labs(x = 'Review score', y = 'Sentiment score', 
                                  title = 'Review score vs. sentiment score', subtitle = 'By year and genre, 2016 to 2019, yearly breakdown')

ggsave('review_vs_sentiment1619_detailed.png', width = 9, height = 30)
```

TBA

```{r ols_modelling, warning=FALSE, message=FALSE}
train_index <- createDataPartition(iris$Species, p = .7, 
                                   list = FALSE, 
                                   times = 1)

data_train <- data[train_index,]

data_test <- data[-train_index,]

nrow(data_test) - sum(data_test$author_name %in% data_train$author_name)

unique(data_test$author_name)[!(unique(data_test$author_name) %in% unique(data_train$author_name))]

unique(data_test$author_title)[!(unique(data_test$author_title) %in% unique(data_train$author_title))]

vars_lev <- c('genre', 'afinn_score', 'bnm')

lev1model <- paste0("score ~ ",paste(vars_lev,collapse = " + "))

ols_modeller <- function(x, data_train) {
  set.seed(42)
  data_train_temp <- data_train
  model_name <- as.character(x)
  model <- train(
    formula(model_name),
    data = data_train,
    method = "lm",
    trControl = train_control)
  list_res <- model
  return(list_res)
}

train_control <- trainControl(method = "cv", number = 10, verboseIter = F)

model <- ols_modeller(lev1model, data_train)

data_predicted <- data_test %>% 
  mutate(predicted_score = predict(model, newdata = data_test))

ggplot(data = data_predicted, aes(x = score, y = predicted_score)) +
  geom_point() +
  xlim(2, 10) +
  ylim(2, 10) +
  geom_abline(slope = 1, intercept = 0, color = 'red') + 
  theme_bw() +
  labs(x = 'Actual score', y = 'Predicted score', 
       title = 'Actual score vs. predicted score', subtitle = 'on the test set')

ggsave('test_results.png')

ggplot(data = data_predicted, aes(x = score, y = predicted_score)) +
  geom_point(size = 0.1) +
  xlim(2, 10) +
  ylim(2, 10) +
  geom_abline(slope = 1, intercept = 0, color = 'red') +
  facet_wrap(~genre) +
  theme_bw() +
  labs(x = 'Actual score', y = 'Predicted score', 
       title = 'Actual score vs. predicted score', subtitle = 'on the test set, by genre')

ggsave('test_results_detailed.png')
```

TBA

```{r word_frequency_1, warning=FALSE, message=FALSE}
summary(data$score)

q1 <- 6.8
q2 <- 7.3
q3 <- 7.7

q1_data <- data %>% filter(score < 6.8)

q2_data <- data %>% filter(score >= 6.8 & score < 7.7)

q3_data <- data %>% filter(score > 7.7)

top_worder <- function(data_input){
  
  text_list <- list()
  log_info('List created')
  
  for (i in 1:nrow(data_input)){
    data <- data_input %>% slice(i) %>% select(artist, review_text)
    #log_info('Data slices')

    text <- strsplit(data$review_text, ' ')
    #log_info('Text split done')
    text <- data_frame(word = unlist(text))
    #log_info('Added word variable')
    text <- text %>% 
      filter(word != '')
    #log_info('Filtered for empty')
    text <- text %>% 
      anti_join(custom_stop_words)
    #log_info('Anti-join done')
    total_rows <- nrow(text)
    text <- text %>% 
      group_by(word) %>% 
      count() %>% 
      summarize(count = n, total_count = total_rows) %>% 
      arrange(-count) %>%
      head(20)
    
    text_list[[i]] <- text 
  }
  
  trial <- rbindlist(text_list)
  
  all_words <- sum(trial$total_count) / length(unique(trial$total_count))
  
  top_words <- trial %>% 
    group_by(word) %>% 
    summarise(total = sum(count), all_words = all_words, share = total/all_words) %>% 
    arrange(-total) 
  
  return(top_words)
}

q1_data_f <- top_worder(q1_data) %>% mutate(segment = 'bottom_25') %>% head(10)

q2_data_f <- top_worder(q2_data) %>% mutate(segment = 'mid_range') %>% head(10)

q3_data_f <- top_worder(q3_data) %>% mutate(segment = 'top_25') %>% head(10)

all_qs <- rbindlist(list(q1_data_f, q2_data_f, q3_data_f))

ggplot(all_qs, aes(x = reorder(word, share), round(share * 100, 2), fill = segment)) +
  geom_col() +
  facet_wrap(~segment, ncol = 3, scales = 'free') +
  coord_flip() +
  theme_bw() +
  labs(x = 'Words', y = 'Share of words (%)', 
       title = 'Most frequently used words', subtitle = 'by ranges of scores, 2016-2019') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill = FALSE)

ggsave('word_freq_q123.png')
```

TBA

```{r word_frequency_2, warning=FALSE, message=FALSE}
genre_list <- list()
i = 1
for (g in unique(q1_data$genre)){
  data_temp <- q1_data %>% filter(genre == g)
  data_temp <- top_worder(data_temp) %>% mutate(segment = g) %>% head(10)
  genre_list[[i]] <- data_temp
  i = i + 1
}

all_genres_freq <- rbindlist(genre_list)

ggplot(all_genres_freq, aes(x = reorder(word, share), round(share * 100, 2), fill = segment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~segment, ncol = 3, scales = 'free') +
  coord_flip() +
  theme_bw() +
  labs(x = 'Words', y = 'Share of words (%)', 
       title = 'Most frequently used words', subtitle = 'by genre, 2016-2019') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill = FALSE)

ggsave('word_freq_genre.png',  width = 9, height = 12)
```

TBA

```{r word_frequency_3, warning=FALSE, message=FALSE}
genre_freqer <- function(data){
  genre_list <- list()
  i = 1
  for (g in unique(data$genre)){
    data_temp <- data %>% filter(genre == g)
    data_temp <- top_worder(data_temp) %>% mutate(segment = g) %>% head(10)
    genre_list[[i]] <- data_temp
    i = i + 1
  }
  
  all_genres_freq <- rbindlist(genre_list)
  
  return(all_genres_freq)
}

q1_data_genre_f <- genre_freqer(q1_data) %>% mutate(quartile = 'bottom_25')
q2_data_genre_f <- genre_freqer(q2_data) %>% mutate(quartile = 'mid_range')
q3_data_genre_f <- genre_freqer(q3_data) %>% mutate(quartile = 'top_25')

all_qs_genre_f <- rbindlist(list(q1_data_genre_f, q2_data_genre_f, q3_data_genre_f))

ggplot(all_qs_genre_f, aes(x = reorder(word, share), round(share * 100, 2), fill = segment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~segment + quartile, ncol = 3, scales = 'free') +
  coord_flip() +
  theme_bw() +
  labs(x = 'Words', y = 'Share of words (%)', 
       title = 'Most frequently used words', subtitle = 'by genre, ranges of scores 2016-2019') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill = FALSE)

ggsave('word_freq_genre_segment.png', width = 9, height = 30)
```

TBA

```{r inverse_frequency, warning=FALSE, message=FALSE}
tf_idfer <- function(data_input){
  text_list <- list()
  
  for (i in 1:nrow(data_input)){
    work_data <- data_input %>% slice(i) %>% select(artist, album, review_text)
    
    artist_to_use <- paste(work_data$artist, work_data$album, sep = '_')
    #log_info('Data slices')
    
    text <- strsplit(work_data$review_text, ' ')
    #log_info('Text split done')
    text <- data_frame(word = unlist(text))
    #log_info('Added word variable')
    text <- text %>% 
      filter(word != '')
    #log_info('Filtered for empty')
    text <- text %>% 
      anti_join(custom_stop_words)
    #log_info('Anti-join done')
    text <- text %>% mutate(artist = artist_to_use)
    
    text_list[[i]] <- text 
  }
  
  text_list <- rbindlist(text_list)
  
  text_list <- text_list %>% count(artist, word, sort = TRUE) %>% 
    bind_tf_idf(word, artist, n) %>% group_by(word) %>% summarise(mean_tf_idf = mean(tf_idf)) %>%
    arrange(-mean_tf_idf) %>% head(20)
  
  return(text_list)
}

tf_idfer(data)

q1_data_idf <- tf_idfer(q1_data) %>% mutate(segment = 'bottom_25') %>% head(10)

q2_data_idf <- tf_idfer(q2_data) %>% mutate(segment = 'mid_range') %>% head(10)

q3_data_idf <- tf_idfer(q3_data) %>% mutate(segment = 'top_25') %>% head(10)

all_qs_idf <- rbindlist(list(q1_data_idf, q2_data_idf, q3_data_idf))

ggplot(all_qs_idf, aes(x = reorder(word, mean_tf_idf), mean_tf_idf, fill = segment)) +
  geom_col() +
  facet_wrap(~segment, ncol = 3, scales = 'free') +
  coord_flip() +
  theme_bw() +
  labs(x = 'Words', y = 'Inverse frequency', 
       title = 'Most prominent words by inverse word frequency', subtitle = 'by ranges of scores 2016-2019') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  guides(fill = FALSE)

ggsave('inv_word_freq_segment.png')
```

TBA